{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lvJDaZQ5Xn6"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTBHpu-e1JDj"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/test/Pascal-part.zip /content/\n",
        "!unzip -n Pascal-part.zip "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VH29rFVtLJVH"
      },
      "outputs": [],
      "source": [
        "!pip install -q evaluate\n",
        "!pip install -q git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q albumentations pytorch-lightning\n",
        "!pip install wandb\n",
        "!wandb login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5H289CrD7iV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import evaluate\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from transformers import MaskFormerForInstanceSegmentation\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "from typing import Dict\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hB_2noa16jzV"
      },
      "outputs": [],
      "source": [
        "\n",
        "preprocessor = MaskFormerImageProcessor(ignore_index=0, reduce_labels=False, do_resize=False, do_rescale=False, do_normalize=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFVRiRVLwRui"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYh17IShr_8e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCXt43XZeE-4"
      },
      "outputs": [],
      "source": [
        "%cd /content/Pascal-part/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52kyNcAIr60t"
      },
      "outputs": [],
      "source": [
        "import albumentations as A\n",
        "\n",
        "\n",
        "\n",
        "train_transform = A.Compose(\n",
        "    [       A.HorizontalFlip(p=0.4),\n",
        "            A.VerticalFlip(p=0.4),\n",
        "            A.Resize(width=Config.width, height=Config.height),\n",
        "       \n",
        "            A.Normalize(mean=ADE_MEAN, std=ADE_STD),\n",
        "    \n",
        "    ]\n",
        ")\n",
        "\n",
        "#optional transforms:\n",
        "optional_transforms = A.Compose(\n",
        "                  A.ShiftScaleRotate(scale_limit=0.5, rotate_limit=(-8, 8), #15\n",
        "                                    shift_limit=0.1, p=1, border_mode=0, value=0.0),\n",
        "                  A.IAAAdditiveGaussianNoise(p=0.2),\n",
        "                  A.IAAPerspective(p=0.5),\n",
        "                  A.OneOf(\n",
        "                      [\n",
        "                          A.CLAHE(p=1),\n",
        "                          A.RandomBrightnessContrast(p=1),\n",
        "                          A.RandomGamma(p=1),\n",
        "                      ],\n",
        "                      p=0.9,\n",
        "                  ),\n",
        "                  A.OneOf(\n",
        "                      [\n",
        "                          A.IAASharpen(p=1),\n",
        "                          A.Blur(blur_limit=3, p=1),\n",
        "                          A.MotionBlur(blur_limit=3, p=1),\n",
        "                      ],\n",
        "                      p=0.9,\n",
        "                  ),\n",
        "                  A.OneOf(\n",
        "                      [\n",
        "                          A.RandomBrightnessContrast(p=1),\n",
        "                          A.HueSaturationValue(p=1),\n",
        "                      ],\n",
        "                      p=0.9,\n",
        "                  ) \n",
        "                  )\n",
        "\n",
        "test_transform = A.Compose([\n",
        "    A.Resize(width=Config.width, height=Config.height),\n",
        "    A.Normalize(mean=ADE_MEAN, std=ADE_STD),\n",
        "\n",
        "])\n",
        "\n",
        "train_dataset = ImageSegmentationDataset(id_path='train_id.txt', transform=train_transform)\n",
        "test_dataset = ImageSegmentationDataset(id_path='val_id.txt', transform=test_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDT_TFAu6cWe"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "  inputs = list(zip(*batch))\n",
        "  \n",
        "  images = inputs[0]\n",
        "  segmentation_maps = inputs[1]\n",
        "\n",
        "  batch = preprocessor(\n",
        "    images,\n",
        "    segmentation_maps=segmentation_maps,\n",
        "    return_tensors=\"pt\",\n",
        "  )\n",
        "  batch[\"original_images\"] = inputs[2]        \n",
        "  batch['original_segmentation_maps'] = inputs[3]\n",
        "  return batch\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=Config.train_batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=Config.train_batch_size, shuffle=False, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSIJCS_lKvAK"
      },
      "outputs": [],
      "source": [
        "#PyTorch\n",
        "ALPHA = 0.5\n",
        "BETA = 0.5\n",
        "GAMMA = 1\n",
        "\n",
        "class FocalTverskyLoss(torch.nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(FocalTverskyLoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1, alpha=ALPHA, beta=BETA, gamma=GAMMA):\n",
        "        \n",
        "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
        "        inputs = torch.sigmoid(inputs)       \n",
        "        \n",
        "        #flatten label and prediction tensors\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "        \n",
        "        #True Positives, False Positives & False Negatives\n",
        "        TP = (inputs * targets).sum()    \n",
        "        FP = ((1-targets) * inputs).sum()\n",
        "        FN = (targets * (1-inputs)).sum()\n",
        "        \n",
        "        Tversky = (TP + smooth) / (TP + alpha*FP + beta*FN + smooth)  \n",
        "        FocalTversky = (1 - Tversky)**gamma\n",
        "                       \n",
        "        return FocalTversky\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKPY0KtqJk0Y"
      },
      "outputs": [],
      "source": [
        "class SegModel(pl.LightningModule):\n",
        "    def __init__(self, train_dataloader=None, validation_dataloader=None):\n",
        "        super(SegModel, self).__init__()\n",
        "        self.train_loader=train_dataloader\n",
        "        self.val_loader=validation_dataloader                \n",
        "        print(self.id2label)    \n",
        "        \n",
        "        self.metric=evaluate.load(\"mean_iou\")\n",
        "\n",
        "        self.args = Config\n",
        "        self.lr = Config.lr\n",
        "        self.id2label = self.args.id2label\n",
        "        self.model = MaskFormerForInstanceSegmentation.from_pretrained(\"facebook/maskformer-swin-small-ade\",\n",
        "                                                                id2label=self.id2label,\n",
        "                                                                ignore_mismatched_sizes=True, mask_feature_size=512)        \n",
        "        self.train_batches = Config.train_batch_size*Config.max_epochs\n",
        "        self.warmup_batches = int(self.train_batches*0.3)\n",
        "    \n",
        "\n",
        "   \n",
        "\n",
        "    def forward(self, *args):\n",
        "        return self.model(args)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return self.train_loader\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return self.val_loader\n",
        "\n",
        "    def transfer_batch_to_device(self, batch, device, dataloader_idx):\n",
        "        #can't stack and move whole batch to device, because \n",
        "        #we need original images and original seg. maps (inconsistent size inside batch)\n",
        "        return batch\n",
        "\n",
        "    def create_optimizer(self):\n",
        "        return torch.optim.AdamW(self.parameters(), lr=self.lr, weight_decay=0.1)\n",
        "            \n",
        "    def lr_warmup_config(self):\n",
        "        def warmup(step):\n",
        "            \"\"\"\n",
        "            This method will be called for ceil(warmup_batches/accum_grad_batches) times,\n",
        "            warmup_steps has been adjusted accordingly\n",
        "            \"\"\"\n",
        "            if self.args.warmup_steps <= 0:\n",
        "                factor = 1\n",
        "            else:\n",
        "                factor = min(step / self.args.warmup_steps, 1)\n",
        "            return factor\n",
        "\n",
        "        opt1 = self.create_optimizer()\n",
        "        return {\n",
        "            'frequency': self.warmup_batches,\n",
        "            'optimizer': opt1,\n",
        "            'lr_scheduler': {\n",
        "                'scheduler': torch.optim.lr_scheduler.LambdaLR(opt1, warmup),\n",
        "                'interval': 'step',\n",
        "                'frequency': 1,\n",
        "                'name': 'lr/warmup'\n",
        "            },\n",
        "        }\n",
        "\n",
        "\n",
        "    def lr_decay_config(self):\n",
        "        opt2 = self.create_optimizer()\n",
        "        return {\n",
        "            'frequency': self.train_batches - self.warmup_batches,\n",
        "            'optimizer': opt2,\n",
        "            'lr_scheduler': {\n",
        "\n",
        "                'scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "                                    opt2, 'min', \n",
        "                                    factor=self.args.lrdecay_factor, \n",
        "                                    patience=self.args.lrdecay_patience,\n",
        "                                    threshold=self.args.lrdecay_threshold, \n",
        "                                    threshold_mode='rel',  verbose=False,\n",
        "                                    \n",
        "                                   ),\n",
        "                'interval': 'epoch',\n",
        "                'frequency': 1,\n",
        "                'monitor': self.args.lrdecay_monitor,\n",
        "                'strict': False,\n",
        "                'name': 'lr/reduce_on_plateau',\n",
        "            }\n",
        "        }\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return (\n",
        "            self.lr_warmup_config(),\n",
        "            self.lr_decay_config()\n",
        "        )\n",
        "\n",
        "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
        "        outputs = self.model(\n",
        "        pixel_values=batch[\"pixel_values\"].to(self.device),\n",
        "                mask_labels=[labels.to(self.device) for labels in batch[\"mask_labels\"]],\n",
        "                class_labels=[labels.to(self.device) for labels in batch[\"class_labels\"]],)\n",
        "        loss = outputs.loss        \n",
        "        self.log(\"train_loss\", loss, logger=True, on_epoch=True)          \n",
        "        return loss\n",
        "\n",
        "    def get_metrics(self, batch, outputs):\n",
        "         original_images = batch[\"original_images\"]\n",
        "        \n",
        "        target_sizes = [(image.shape[0], image.shape[1]) for image in original_images]\n",
        "      \n",
        "        predicted_segmentation_maps = preprocessor.post_process_semantic_segmentation(outputs,\n",
        "                                                                                        target_sizes=target_sizes)\n",
        "        ground_truth_segmentation_maps = batch[\"original_segmentation_maps\"]\n",
        "        metrics =self.metric.compute(references=ground_truth_segmentation_maps, \n",
        "                                     predictions=predicted_segmentation_maps,\n",
        "                                     num_labels=self.args.num_labels, \n",
        "                                     ignore_index=self.arg.ignore_index)\n",
        "        return metrics\n",
        "\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "\n",
        "        self.log('step', batch_idx, prog_bar=True)\n",
        "\n",
        "        outputs = self.model(\n",
        "            pixel_values=batch[\"pixel_values\"].to(self.device),\n",
        "        )     \n",
        "        metrics = self.get_metrics(outputs=outputs, batch=batch)\n",
        "        iou = metrics['mean_iou']\n",
        "        acc = metrics['mean_accuracy']\n",
        "        self.log('val_iou', iou,logger=True,prog_bar=True, on_epoch=True, on_step=True)\n",
        "        self.log('val_acc', acc,logger=True )\n",
        "    \n",
        "    def test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjyGo0bpMQ87"
      },
      "outputs": [],
      "source": [
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from pytorch_lightning.callbacks import LearningRateMonitor\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "wandb_logger = WandbLogger(project='mil_test', entity='sapsapfear')\n",
        "lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
        "checkpoint_callback = ModelCheckpoint(dirpath='/content/drive/MyDrive/test/', )\n",
        "# Init ModelCheckpoint callback, monitoring 'val_loss'\n",
        "# checkpoint_callback = ModelCheckpoint(monitor=\"val_iou\")\n",
        "model = SegModel(train_dataloader= train_dataloader,validation_dataloader= test_dataloader)\n",
        "trainer = pl.Trainer(logger=wandb_logger, \n",
        "                    gpus=1\n",
        "                     , \n",
        "                    #  strategy=DeepSpeedPlugin(deepspeed_config), \n",
        "                    #  strategy = \"deepspeed_stage_2_offload\",\n",
        "                     precision=16,\n",
        "                     default_root_dir='/content/drive/MyDrive/test/',\n",
        "                     callbacks=[lr_monitor, checkpoint_callback],\n",
        "                     log_every_n_steps=1,\n",
        "                     min_epochs=1,\n",
        "                     check_val_every_n_epoch=2,\n",
        "\n",
        "                     )\n",
        "trainer.fit(model, ckpt_path='/content/drive/MyDrive/test/epoch=51-step=28.ckpt')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "mil_test",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "7321db51a497827ba14741a635b123d482561ce238fc0a1c583ce5b482801bdb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
